#!/bin/bash

# vLLM —Å–µ—Ä–≤–µ—Ä —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

set -e

# –ó–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
DEFAULT_MODEL="Qwen/Qwen2.5-7B-Instruct"
PORT=8000
HOST="0.0.0.0"
CPU_OFFLOAD_GB=""

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π: –Ω–∞–∑–≤–∞–Ω–∏–µ => "model_id|gpu_mem|max_len|quant|special_flags|sampling_params"
declare -A MODELS=(
    # Qwen –º–æ–¥–µ–ª–∏
    ["qwen-7b"]="Qwen/Qwen2.5-7B-Instruct|0.85|8192||||"
    ["qwen-14b"]="Qwen/Qwen2.5-14B-Instruct|0.90|8192||||"
    ["qwen-32b"]="Qwen/Qwen2.5-32B-Instruct|0.95|4096||||"
    ["qwen-72b"]="Qwen/Qwen2.5-72B-Instruct-AWQ|0.95|4096|awq|||"
    ["qwen-math-7b"]="Qwen/Qwen2.5-Math-7B-Instruct|0.85|4096||||"
    ["qwen-math-72b"]="Qwen/Qwen2.5-Math-72B-Instruct-AWQ|0.95|4096|awq|||"
    
    # Qwen Vision-Language –º–æ–¥–µ–ª–∏ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)
    ["qwen3-vl-2b"]="unsloth/Qwen3-VL-2B-Instruct|0.85|8192||vlm|top_p=0.8,top_k=20,temperature=0.7,presence_penalty=1.5"
    
    # Llama –º–æ–¥–µ–ª–∏ (—Ç—Ä–µ–±—É—é—Ç gated access!)
    ["llama-3.2-3b"]="meta-llama/Llama-3.2-3B-Instruct|0.80|8192||||"
    ["llama-3.1-8b"]="meta-llama/Llama-3.1-8B-Instruct|0.85|8192||||"
    ["llama-3.3-70b"]="casperhansen/llama-3.3-70b-instruct-awq|0.85|8192|awq|||"
    ["llama-3.1-70b"]="hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4|0.95|8192|awq|||"
    
    # –î—Ä—É–≥–∏–µ –º–æ–¥–µ–ª–∏
    ["mistral-7b"]="mistralai/Mistral-7B-Instruct-v0.3|0.85|8192||||"
    ["mistral-small"]="mistralai/Mistral-Small-Instruct-2409|0.95|8192||||"
    ["deepseek-math"]="deepseek-ai/deepseek-math-7b-instruct|0.85|8192||||"
)

# –§—É–Ω–∫—Ü–∏—è –ø–æ–º–æ—â–∏
show_help() {
    cat << EOF
üöÄ vLLM Server Launcher

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: 
    ./start_server.sh [OPTIONS]

–û–ø—Ü–∏–∏:
    --model <name>           –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: qwen-7b)
    --port <port>            –ü–æ—Ä—Ç —Å–µ—Ä–≤–µ—Ä–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 8000)
    --host <host>            Host –∞–¥—Ä–µ—Å (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 0.0.0.0)
    --cpu-offload-gb <gb>    –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ GB RAM –¥–ª—è CPU –æ—Ñ—Ñ–ª–æ–∞–¥–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    --help                   –ü–æ–∫–∞–∑–∞—Ç—å —ç—Ç—É —Å–ø—Ä–∞–≤–∫—É

–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ (–ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é –º–æ—â–Ω–æ—Å—Ç–∏):

üìä 2-3B –º–æ–¥–µ–ª–∏ (–æ—á–µ–Ω—å –±—ã—Å—Ç—Ä—ã–µ, ~4-6GB VRAM):
    qwen3-vl-2b       unsloth/Qwen3-VL-2B-Instruct [VLM]
                      Vision-Language –º–æ–¥–µ–ª—å, —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ + —Ç–µ–∫—Å—Ç–æ–º
                      –ö–æ–Ω—Ç–µ–∫—Å—Ç: 8K, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –¥–æ 10 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ø—Ä–æ–º–ø—Ç–µ
                      –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:
                        - top_p: 0.8, top_k: 20, temperature: 0.7
                        - presence_penalty: 1.5 (–¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è)
                        - Flash Attention –≤–∫–ª—é—á–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏

üìä 7B –º–æ–¥–µ–ª–∏ (–±—ã—Å—Ç—Ä—ã–µ, ~14GB VRAM):
    qwen-7b           Qwen/Qwen2.5-7B-Instruct
    qwen-math-7b      Qwen/Qwen2.5-Math-7B-Instruct
    mistral-7b        mistralai/Mistral-7B-Instruct-v0.3
    deepseek-math     deepseek-ai/deepseek-math-7b-instruct

üìä 14B –º–æ–¥–µ–ª–∏ (–±–∞–ª–∞–Ω—Å, ~28GB VRAM):
    qwen-14b          Qwen/Qwen2.5-14B-Instruct

üìä 24-32B –º–æ–¥–µ–ª–∏ (–º–æ—â–Ω—ã–µ, ~30GB VRAM):
    mistral-small     mistralai/Mistral-Small-Instruct-2409 (24B)
    qwen-32b          Qwen/Qwen2.5-32B-Instruct

üìä 72B –º–æ–¥–µ–ª–∏ (–º–∞–∫—Å–∏–º—É–º, AWQ 4-bit, ~31GB VRAM):
    qwen-72b          Qwen/Qwen2.5-72B-Instruct-AWQ
    qwen-math-72b     Qwen/Qwen2.5-Math-72B-Instruct-AWQ

–ü—Ä–∏–º–µ—Ä—ã:
    ./start_server.sh
    ./start_server.sh --model qwen3-vl-2b
    ./start_server.sh --model qwen-math-72b
    ./start_server.sh --model qwen-14b --port 8001

–ü–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ –∞–¥—Ä–µ—Å—É:
    http://localhost:$PORT/v1

EOF
}

# –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
MODEL_NAME="qwen-7b"

while [[ $# -gt 0 ]]; do
    case $1 in
        --model) MODEL_NAME="$2"; shift 2 ;;
        --port) PORT="$2"; shift 2 ;;
        --host) HOST="$2"; shift 2 ;;
        --cpu-offload-gb) CPU_OFFLOAD_GB="$2"; shift 2 ;;
        --help|-h) show_help; exit 0 ;;
        *) echo "‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∞—Ä–≥—É–º–µ–Ω—Ç: $1"; echo "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --help –¥–ª—è —Å–ø—Ä–∞–≤–∫–∏"; exit 1 ;;
    esac
done

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –º–æ–¥–µ–ª—å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
if [[ ! -v MODELS[$MODEL_NAME] ]]; then
    echo "‚ùå –û—à–∏–±–∫–∞: –ú–æ–¥–µ–ª—å '$MODEL_NAME' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
    echo ""
    echo "–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:"
    for key in "${!MODELS[@]}"; do
        echo "  - $key"
    done | sort
    echo ""
    echo "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --help –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"
    exit 1
fi

# –†–∞–∑–±–æ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏
IFS='|' read -r MODEL_ID GPU_MEM MAX_LEN QUANT SPECIAL SAMPLING <<< "${MODELS[$MODEL_NAME]}"

# –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã —á–µ—Ä–µ–∑ –º–∞—Å—Å–∏–≤
CMD_ARGS=(
    python -m vllm.entrypoints.openai.api_server
    --model "$MODEL_ID"
    --host "$HOST"
    --port "$PORT"
    --trust-remote-code
    --gpu-memory-utilization "$GPU_MEM"
    --max-model-len "$MAX_LEN"
    --served-model-name vllm-model
)

# –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è
[[ -n "$QUANT" ]] && CMD_ARGS+=(--quantization "$QUANT")

# CPU offload
[[ -n "$CPU_OFFLOAD_GB" ]] && CMD_ARGS+=(--cpu-offload-gb "$CPU_OFFLOAD_GB")

# VLM —Ñ–ª–∞–≥–∏
if [[ "$SPECIAL" == "vlm" ]]; then
    CMD_ARGS+=(
        --limit-mm-per-prompt '{"image": 10}'
        --enable-prefix-caching
        --enable-chunked-prefill
        --max-num-batched-tokens 8192
        --max-num-seqs 256
    )
    IS_VLM=true
else
    IS_VLM=false
fi

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
if [[ -n "$SAMPLING" ]]; then
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º "key=value,key=value" –≤ JSON
    SAMPLING_JSON="{"
    IFS=',' read -ra PARAMS <<< "$SAMPLING"
    for i in "${!PARAMS[@]}"; do
        IFS='=' read -r key value <<< "${PARAMS[$i]}"
        [[ $i -gt 0 ]] && SAMPLING_JSON+=","
        SAMPLING_JSON+="\"$key\": $value"
    done
    SAMPLING_JSON+="}"
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∞—Ä–≥—É–º–µ–Ω—Ç—ã (–µ—Å–ª–∏ vLLM –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç)
    # –í —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏ vLLM —ç—Ç–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ –∑–∞–ø—Ä–æ—Å—ã
    HAS_SAMPLING=true
else
    HAS_SAMPLING=false
fi

# –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
echo "üöÄ –ó–∞–ø—É—Å–∫ vLLM —Å–µ—Ä–≤–µ—Ä–∞"
echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
echo "üì¶ –ú–æ–¥–µ–ª—å:        $MODEL_NAME"
echo "üîñ Model ID:      $MODEL_ID"
echo "üåê –ê–¥—Ä–µ—Å:         http://$HOST:$PORT"
echo "üíæ GPU Memory:    ${GPU_MEM}0%"
echo "üìè Max Length:    $MAX_LEN"

if [[ "$IS_VLM" == true ]]; then
    echo "üñºÔ∏è  Type:          Vision-Language Model (VLM)"
    echo "üì∏ Images:        –î–æ 10 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ø—Ä–æ–º–ø—Ç–µ"
    echo "üî• Flash Attn:    Enabled (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)"
fi

if [[ -n "$QUANT" ]]; then
    echo "üî¢ Quantization:  $QUANT"
fi

if [[ -n "$CPU_OFFLOAD_GB" ]]; then
    echo "üíø CPU Offload:   ${CPU_OFFLOAD_GB} GB"
fi

if [[ "$HAS_SAMPLING" == true ]]; then
    echo ""
    echo "‚öôÔ∏è  –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é:"
    echo "   $SAMPLING_JSON"
fi

echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
echo ""

# –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU
if command -v nvidia-smi &> /dev/null; then
    GPU_NAME=$(nvidia-smi --query-gpu=name --format=csv,noheader | head -1)
    GPU_MEM_TOTAL=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits | head -1)
    echo "üéÆ GPU:           $GPU_NAME ($GPU_MEM_TOTAL MB)"
else
    echo "‚ö†Ô∏è  nvidia-smi –Ω–µ –Ω–∞–π–¥–µ–Ω"
fi

echo ""
echo "‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ (30-90 —Å–µ–∫—É–Ω–¥)..."
echo ""

if [[ "$IS_VLM" == true ]]; then
    echo "üí° –ü—Ä–∏–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º:"
    echo ""
    echo "curl http://localhost:$PORT/v1/chat/completions \\"
    echo "  -H 'Content-Type: application/json' \\"
    echo "  -d '{"
    echo "    \"model\": \"vllm-model\","
    echo "    \"messages\": [{"
    echo "      \"role\": \"user\","
    echo "      \"content\": ["
    echo "        {\"type\": \"text\", \"text\": \"–ß—Ç–æ –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ?\"},"
    echo "        {\"type\": \"image_url\", \"image_url\": {\"url\": \"https://...\"}}"
    echo "      ]"
    echo "    }],"
    
    if [[ "$HAS_SAMPLING" == true ]]; then
        echo "    \"top_p\": 0.8,"
        echo "    \"top_k\": 20,"
        echo "    \"temperature\": 0.7,"
        echo "    \"presence_penalty\": 1.5,"
    fi
    
    echo "    \"max_tokens\": 500"
    echo "  }'"
    echo ""
fi

echo "–î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞–∂–º–∏—Ç–µ Ctrl+C"
echo ""

# –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞
"${CMD_ARGS[@]}"